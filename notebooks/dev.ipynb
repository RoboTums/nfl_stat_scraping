{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4, requests, time, string\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we want to replicate Get_and_store_all_players_names_and_ids\n",
    "\n",
    "recovering the csvs is a bit more unreliable. we use selenium to collect their names, then we do the rest. \n",
    "\n",
    "requirements: selenium. Geckodriver. pandas, lxml, bs4, requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "import pandas as pd\n",
    "import string\n",
    "from time import sleep\n",
    "\n",
    "class nfl_player_link_scraper:\n",
    "    def __init__(self):\n",
    "        self.drv = webdriver.Firefox()\n",
    "        self.upper_alph = string.ascii_uppercase\n",
    "        self.paginate_class = 'nfl-o-table-pagination__next'\n",
    "        self.base_player_df = None\n",
    "        self.ignored_exceptions = (NoSuchElementException,StaleElementReferenceException,)\n",
    "        \n",
    "    # gets player info and links to profiles, from all the players who's last name starts with letter. \n",
    "    # returns a dataframe of PlayerName | current Team | Position | Status | Link | \n",
    "    def get_curr_players_with_last_name(self,letter):\n",
    "        #aggregate list is for the pandas concat coming later.\n",
    "        aggregate_list = []\n",
    "        url = f\"http://www.nfl.com/players/active/{letter}\"\n",
    "\n",
    "        self.drv.get(url)\n",
    "\n",
    "\n",
    "        # we handle pagination by knowing that they give us the max num of players. Each page renders up to 100 players, so we keep incrementing until we hit max.\n",
    "        max_players_to_scrape = int(self.drv.find_element_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/header').text.split(' ')[0])\n",
    "        print(f'preparing to scrape {max_players_to_scrape} players starting with {letter}. \\n Selenium will visit {max_players_to_scrape//100+1} pages.\\n')\n",
    "\n",
    "        # We need to screen for players that actually have links. Otherwise, their data isnt useful. \n",
    "        WebDriverWait(self.drv, 3,ignored_exceptions=self.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a')))\n",
    "        link_web_obj = self.drv.find_elements_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a')\n",
    "\n",
    "        screening_list = [link.text for link in link_web_obj if link.get_attribute('href') is not None]\n",
    "        #create dataframe to represent the current page. \n",
    "        curr_df = pd.read_html(url)[0]\n",
    "        curr_df = curr_df[curr_df['Player'].isin(screening_list)]\n",
    "        curr_df['link'] = [link.get_attribute('href') for link in link_web_obj]\n",
    "        aggregate_list.append(curr_df)\n",
    "        \n",
    "        current_players_scraped = curr_df.shape[0]\n",
    "        #handle pagination. \n",
    "        while current_players_scraped < max_players_to_scrape:\n",
    "            #click next button. \n",
    "            paginate_btn = WebDriverWait(self.drv, 3,ignored_exceptions=self.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.CLASS_NAME, self.paginate_class)))\n",
    "            paginate_btn.click()\n",
    "            url = self.drv.current_url\n",
    "\n",
    "            WebDriverWait(self.drv, 3,ignored_exceptions=self.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a')))\n",
    "            link_web_obj = self.drv.find_elements_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a')\n",
    "\n",
    "            curr_df = pd.read_html(url)[0]\n",
    "            \n",
    "            sleep(2)\n",
    "\n",
    "            screening_list = [link.text for link in link_web_obj if link.get_attribute('href') is not None]\n",
    "            curr_df = curr_df[curr_df['Player'].isin(screening_list)]\n",
    "            curr_df['link'] = [link.get_attribute('href') for link in link_web_obj]\n",
    "            aggregate_list.append(curr_df)\n",
    "\n",
    "            print(f\"Scraped around:{round(current_players_scraped/max_players_to_scrape,2)*100}% of players starting with {letter}\")\n",
    "\n",
    "            if current_players_scraped + curr_df.shape[0] >= max_players_to_scrape:\n",
    "                return pd.concat(aggregate_list)\n",
    "            else:\n",
    "                current_players_scraped+= curr_df.shape[0]\n",
    "    def get_historical_players_with_last_name(self,letter):\n",
    "        #aggregate list is for the pandas concat coming later.\n",
    "        aggregate_list = []\n",
    "        url = f\"http://www.nfl.com/players/retired/{letter}\"\n",
    "\n",
    "        self.drv.get(url)\n",
    "\n",
    "\n",
    "        # we handle pagination by knowing that they give us the max num of players. Each page renders up to 100 players, so we keep incrementing until we hit max.\n",
    "        max_players_to_scrape = int(self.drv.find_element_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/header').text.split(' ')[0])\n",
    "        print(f'preparing to scrape {max_players_to_scrape} players starting with {letter}. \\n Selenium will visit {max_players_to_scrape//100+1} pages.\\n')\n",
    "\n",
    "\n",
    "        # We need to screen for players that actually have links. Otherwise, their data isnt useful. \n",
    "        awaited = WebDriverWait(self.drv, 3,ignored_exceptions=self.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/section[2]/div/div/div/div/table')))\n",
    "        link_web_obj = awaited.find_elements_by_tag_name('a')\n",
    "        screening_list = [link.text for link in link_web_obj if link.get_attribute('href') is not None]\n",
    "        #create dataframe to represent the current page. \n",
    "        curr_df = pd.read_html(url)[0]\n",
    "        curr_df = curr_df[curr_df['Player'].isin(screening_list)]\n",
    "        curr_df['link'] = [link.get_attribute('href') for link in link_web_obj]\n",
    "        aggregate_list.append(curr_df)\n",
    "        current_players_scraped = curr_df.shape[0]\n",
    "\n",
    "        #handle pagination. \n",
    "        while current_players_scraped < max_players_to_scrape:\n",
    "            #click next button. \n",
    "            paginate_btn = WebDriverWait(self.drv, 3,ignored_exceptions=self.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.CLASS_NAME, self.paginate_class)))\n",
    "            paginate_btn.click()\n",
    "            url = self.drv.current_url\n",
    "            awaited = WebDriverWait(self.drv, 7,ignored_exceptions=self.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a')))\n",
    "            link_web_obj = awaited.find_elements_by_tag_name('a')\n",
    "            \n",
    "            curr_df = pd.read_html(url)[0]\n",
    "\n",
    "            curr_df = curr_df[curr_df['Player'].isin(screening_list)]\n",
    "            curr_df['link'] = [link.get_attribute('href') for link in link_web_obj]\n",
    "            aggregate_list.append(curr_df)\n",
    "            \n",
    "            print(f\"Scraped around:{round(current_players_scraped/max_players_to_scrape,2)*100}% of players starting with {letter}\")\n",
    "\n",
    "            if current_players_scraped + curr_df.shape[0] >= max_players_to_scrape:\n",
    "                return pd.concat(aggregate_list)\n",
    "            else:\n",
    "                current_players_scraped+= curr_df.shape[0]\n",
    "\n",
    "    #Void fcn that gets all current_players and writes them to a CSV\n",
    "    def get_current_player_links_df(self):\n",
    "        aggregate_list = []\n",
    "        failure_list = []\n",
    "        for letter in self.upper_alph:\n",
    "            try:\n",
    "                aggregate_list.append(self.get_curr_players_with_last_name(letter))\n",
    "            except ValueError:\n",
    "                print(f\"value error on {letter}\")\n",
    "                failure_list.append(letter)\n",
    "\n",
    "        #value errors are really hard to replicate, might be due to dom rendering. So we do a second pass. \n",
    "        for failure in failure_list:\n",
    "            try:\n",
    "                aggregate_list.append(self.get_curr_players_with_last_name(failure))\n",
    "            except ValueError:\n",
    "                print(\"Bug in letter \", letter)\n",
    "\n",
    "        self.base_player_df = pd.concat(aggregate_list)\n",
    "\n",
    "        print(f'successfully scraped {self.base_player_df.shape[0]} current players.')\n",
    "\n",
    "        self.base_player_df.to_csv(\"../data/curr_player_names_links.csv\")\n",
    "        \n",
    "        \n",
    "    #Void fcn that gets all current_players and writes them to a CSV\n",
    "\n",
    "    def get_historical_player_links_df(self):\n",
    "        aggregate_list = []\n",
    "        failure_list = []\n",
    "        for letter in self.upper_alph:\n",
    "            try:\n",
    "                aggregate_list.append(self.get_historical_players_with_last_name(letter))\n",
    "            except ValueError:\n",
    "                print(f\"value error on {letter}\")\n",
    "                failure_list.append(letter)\n",
    "\n",
    "        #value errors are really hard to replicate, might be due to dom rendering. So we do a second pass. \n",
    "        for failure in failure_list:\n",
    "            print(f\"Rerunning scraping for players of: {failure}\")\n",
    "            try:\n",
    "                aggregate_list.append(self.get_historical_players_with_last_name(failure))\n",
    "            except ValueError:\n",
    "                print(\"Bug in letter \", letter)\n",
    "\n",
    "        self.base_player_df = pd.concat(aggregate_list)\n",
    "\n",
    "        print(f'successfully scraped {self.base_player_df.shape[0]} historical players.')\n",
    "\n",
    "        self.base_player_df.to_csv(\"../data/hist_player_names_links.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, activate selenium.\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.get('http://www.nfl.com/players/active/a')\n",
    "driver.find_element_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/footer/div/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "player_table = driver.find_elements_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_html('http://www.nfl.com/players/active/a',header=0)[0]\n",
    "links = [x.get_attribute('href') for x in player_table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_html('https://www.nfl.com/players/active/a',header=0)[0]\n",
    "test['links']=links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Current Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Status</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kyle Juszczyk</td>\n",
       "      <td>San Francisco 49ers</td>\n",
       "      <td>FB</td>\n",
       "      <td>ACT</td>\n",
       "      <td>https://www.nfl.com/players/kyle-juszczyk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luke Juriga</td>\n",
       "      <td>Philadelphia Eagles</td>\n",
       "      <td>C</td>\n",
       "      <td>ACT</td>\n",
       "      <td>https://www.nfl.com/players/luke-juriga/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colton Jumper</td>\n",
       "      <td>New Orleans Saints</td>\n",
       "      <td>LB</td>\n",
       "      <td>UFA</td>\n",
       "      <td>https://www.nfl.com/players/colton-jumper/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jalen Julius</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>SAF</td>\n",
       "      <td>ACT</td>\n",
       "      <td>https://www.nfl.com/players/jalen-julius/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Judon</td>\n",
       "      <td>Baltimore Ravens</td>\n",
       "      <td>OLB</td>\n",
       "      <td>ACT</td>\n",
       "      <td>https://www.nfl.com/players/matt-judon/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Myles Jack</td>\n",
       "      <td>Jacksonville Jaguars</td>\n",
       "      <td>OLB</td>\n",
       "      <td>ACT</td>\n",
       "      <td>https://www.nfl.com/players/myles-jack/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Joe Jackson</td>\n",
       "      <td>Cleveland Browns</td>\n",
       "      <td>DE</td>\n",
       "      <td>ACT</td>\n",
       "      <td>https://www.nfl.com/players/joe-jackson/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Mike Jackson</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>CB</td>\n",
       "      <td>DEV</td>\n",
       "      <td>https://www.nfl.com/players/mike-jackson/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Branden Jackson</td>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>DE</td>\n",
       "      <td>RES</td>\n",
       "      <td>https://www.nfl.com/players/branden-jackson/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Bennett Jackson</td>\n",
       "      <td>New York Jets</td>\n",
       "      <td>SAF</td>\n",
       "      <td>DEV</td>\n",
       "      <td>https://www.nfl.com/players/bennett-jackson/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player          Current Team Position Status  \\\n",
       "0     Kyle Juszczyk   San Francisco 49ers       FB    ACT   \n",
       "1       Luke Juriga   Philadelphia Eagles        C    ACT   \n",
       "2     Colton Jumper    New Orleans Saints       LB    UFA   \n",
       "3      Jalen Julius    Kansas City Chiefs      SAF    ACT   \n",
       "4        Matt Judon      Baltimore Ravens      OLB    ACT   \n",
       "..              ...                   ...      ...    ...   \n",
       "69       Myles Jack  Jacksonville Jaguars      OLB    ACT   \n",
       "70      Joe Jackson      Cleveland Browns       DE    ACT   \n",
       "71     Mike Jackson  New England Patriots       CB    DEV   \n",
       "72  Branden Jackson      Seattle Seahawks       DE    RES   \n",
       "73  Bennett Jackson         New York Jets      SAF    DEV   \n",
       "\n",
       "                                            link  \n",
       "0     https://www.nfl.com/players/kyle-juszczyk/  \n",
       "1       https://www.nfl.com/players/luke-juriga/  \n",
       "2     https://www.nfl.com/players/colton-jumper/  \n",
       "3      https://www.nfl.com/players/jalen-julius/  \n",
       "4        https://www.nfl.com/players/matt-judon/  \n",
       "..                                           ...  \n",
       "69       https://www.nfl.com/players/myles-jack/  \n",
       "70      https://www.nfl.com/players/joe-jackson/  \n",
       "71     https://www.nfl.com/players/mike-jackson/  \n",
       "72  https://www.nfl.com/players/branden-jackson/  \n",
       "73  https://www.nfl.com/players/bennett-jackson/  \n",
       "\n",
       "[174 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider = nfl_player_link_scraper()\n",
    "spider.get_curr_players_with_last_name('J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = [x.text for x in spider.drv.find_elements_by_xpath('/html/body/div[3]/main/section[2]/div/div/div/div/table/tbody/tr/td/div/a') if x.get_attribute('href') is not None]\n",
    "curr_table = pd.read_html(spider.drv.current_url,header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = nfl_player_link_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing to scrape 1275 players starting with A. \n",
      " Selenium will visit 13 pages.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-16d546efe304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_historical_players_with_last_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-7c39f13c34b5>\u001b[0m in \u001b[0;36mget_historical_players_with_last_name\u001b[0;34m(self, letter)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mcurr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Player'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreening_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mcurr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlink_web_obj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0maggregate_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_scraping/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_scraping/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3114\u001b[0m         \"\"\"\n\u001b[1;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_scraping/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3764\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_scraping/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \"\"\"\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    748\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (100)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = WebDriverWait(scraper.drv, 3,ignored_exceptions=scraper.ignored_exceptions).until(expected_conditions.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/section[2]/div/div/div/div/table')))\n",
    "d=f.find_elements_by_tag_name('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.nfl.com/players/bill-anderson/',\n",
       " 'https://www.nfl.com/players/bill-anderson-3/',\n",
       " 'https://www.nfl.com/players/bill-andrews/',\n",
       " 'https://www.nfl.com/players/bill-applegate/',\n",
       " 'https://www.nfl.com/players/bill-armstrong/',\n",
       " 'https://www.nfl.com/players/bill-armstrong-2/',\n",
       " 'https://www.nfl.com/players/bill-ashbaugh/',\n",
       " 'https://www.nfl.com/players/bill-atessis/',\n",
       " 'https://www.nfl.com/players/bill-athey/',\n",
       " 'https://www.nfl.com/players/bill-atkins/',\n",
       " 'https://www.nfl.com/players/bill-austin/',\n",
       " 'https://www.nfl.com/players/bill-austin-2/',\n",
       " 'https://www.nfl.com/players/bill-ayre/',\n",
       " 'https://www.nfl.com/players/billy-alford/',\n",
       " 'https://www.nfl.com/players/billy-allen/',\n",
       " 'https://www.nfl.com/players/billy-alsbrooks/',\n",
       " 'https://www.nfl.com/players/billy-anderson-2/',\n",
       " 'https://www.nfl.com/players/billy-anderson/',\n",
       " 'https://www.nfl.com/players/billy-andrews/',\n",
       " 'https://www.nfl.com/players/billy-ard/',\n",
       " 'https://www.nfl.com/players/billy-atkins/',\n",
       " 'https://www.nfl.com/players/billy-austin/',\n",
       " 'https://www.nfl.com/players/billy-austin-2/',\n",
       " 'https://www.nfl.com/players/billy-austin-3/',\n",
       " 'https://www.nfl.com/players/billy-autrey/',\n",
       " 'https://www.nfl.com/players/billy-joe-aldridge/',\n",
       " 'https://www.nfl.com/players/billy-ray-adams/',\n",
       " 'https://www.nfl.com/players/blake-annen/',\n",
       " 'https://www.nfl.com/players/blue-adams/',\n",
       " 'https://www.nfl.com/players/bob-adams/',\n",
       " 'https://www.nfl.com/players/bob-adams-2/',\n",
       " 'https://www.nfl.com/players/bob-adkins/',\n",
       " 'https://www.nfl.com/players/bob-agler/',\n",
       " 'https://www.nfl.com/players/bob-albert/',\n",
       " 'https://www.nfl.com/players/bob-albrecht/',\n",
       " 'https://www.nfl.com/players/bob-alexander/',\n",
       " 'https://www.nfl.com/players/bob-allman/',\n",
       " 'https://www.nfl.com/players/bob-anahu/',\n",
       " 'https://www.nfl.com/players/bob-anderson/',\n",
       " 'https://www.nfl.com/players/bob-anderson-2/',\n",
       " 'https://www.nfl.com/players/bob-angie/',\n",
       " 'https://www.nfl.com/players/bob-antkowiak/',\n",
       " 'https://www.nfl.com/players/bob-apisa/',\n",
       " 'https://www.nfl.com/players/bob-argus/',\n",
       " 'https://www.nfl.com/players/bob-armstrong/',\n",
       " 'https://www.nfl.com/players/bob-asher/',\n",
       " 'https://www.nfl.com/players/bob-atha/',\n",
       " 'https://www.nfl.com/players/bob-atkins/',\n",
       " 'https://www.nfl.com/players/bob-avellini/',\n",
       " 'https://www.nfl.com/players/bobby-abrams/',\n",
       " 'https://www.nfl.com/players/bobby-anderson/',\n",
       " 'https://www.nfl.com/players/boris-anyama/',\n",
       " 'https://www.nfl.com/players/bosley-allen/',\n",
       " 'https://www.nfl.com/players/brad-anderson/',\n",
       " 'https://www.nfl.com/players/bralon-addison/',\n",
       " 'https://www.nfl.com/players/branden-albert/',\n",
       " 'https://www.nfl.com/players/brandon-anderson/',\n",
       " 'https://www.nfl.com/players/brandon-archer/',\n",
       " 'https://www.nfl.com/players/brendon-ayanbadejo/',\n",
       " 'https://www.nfl.com/players/brent-adams/',\n",
       " 'https://www.nfl.com/players/brent-alexander/',\n",
       " 'https://www.nfl.com/players/brian-aikins/',\n",
       " 'https://www.nfl.com/players/brian-alford/',\n",
       " 'https://www.nfl.com/players/brian-allen-2/',\n",
       " 'https://www.nfl.com/players/brian-allen-3/',\n",
       " 'https://www.nfl.com/players/brian-allred/',\n",
       " 'https://www.nfl.com/players/brian-arnfelt/',\n",
       " 'https://www.nfl.com/players/brian-atkinson/',\n",
       " 'https://www.nfl.com/players/brice-abrams/',\n",
       " 'https://www.nfl.com/players/bruce-adams/',\n",
       " 'https://www.nfl.com/players/bruce-adrine/',\n",
       " 'https://www.nfl.com/players/bruce-airheart/',\n",
       " 'https://www.nfl.com/players/bruce-alexander/',\n",
       " 'https://www.nfl.com/players/bruce-alford-2/',\n",
       " 'https://www.nfl.com/players/bruce-alford/',\n",
       " 'https://www.nfl.com/players/bruce-allen/',\n",
       " 'https://www.nfl.com/players/bruce-anderson-2/',\n",
       " 'https://www.nfl.com/players/bruce-armstrong/',\n",
       " 'https://www.nfl.com/players/bruno-ashley/',\n",
       " 'https://www.nfl.com/players/bryan-addison/',\n",
       " 'https://www.nfl.com/players/bryan-anderson/',\n",
       " 'https://www.nfl.com/players/bryan-anderson-2/',\n",
       " 'https://www.nfl.com/players/bryan-andrews/',\n",
       " 'https://www.nfl.com/players/bryson-albright/',\n",
       " 'https://www.nfl.com/players/bud-abell/',\n",
       " 'https://www.nfl.com/players/buddy-allen/',\n",
       " 'https://www.nfl.com/players/buddy-alliston/',\n",
       " 'https://www.nfl.com/players/buddy-aydelette/',\n",
       " 'https://www.nfl.com/players/burl-atcheson/',\n",
       " 'https://www.nfl.com/players/butch-allison/',\n",
       " 'https://www.nfl.com/players/butch-avinger/',\n",
       " 'https://www.nfl.com/players/buzzy-allert/',\n",
       " 'https://www.nfl.com/players/c-j-ah-you/',\n",
       " 'https://www.nfl.com/players/c-j-akins/',\n",
       " 'https://www.nfl.com/players/caleb-azubike/',\n",
       " 'https://www.nfl.com/players/calvin-armstrong/',\n",
       " 'https://www.nfl.com/players/cameron-artis-payne/',\n",
       " 'https://www.nfl.com/players/carl-aikens/',\n",
       " 'https://www.nfl.com/players/carl-allen/',\n",
       " 'https://www.nfl.com/players/carl-allen-2/']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.get_attribute('href') for x in d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
